{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebc26d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:17.741029Z",
     "start_time": "2022-06-25T16:52:16.267442Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74539e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:18.074515Z",
     "start_time": "2022-06-25T16:52:17.742959Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/survey_data_before_pre_processing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88034444",
   "metadata": {},
   "source": [
    "### Convert all Refused to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02892c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:18.536986Z",
     "start_time": "2022-06-25T16:52:18.076446Z"
    }
   },
   "outputs": [],
   "source": [
    "# map every Refused to np.nan\n",
    "df = df.applymap(lambda x: np.nan if x == 'Refused' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f8092",
   "metadata": {},
   "source": [
    "### Ordinal Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67690dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:18.568414Z",
     "start_time": "2022-06-25T16:52:18.540995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replacing nulls in these columns with 'none' to help with ordinal encoding\n",
    "df['cause_recoded'].fillna('none', inplace=True)\n",
    "df['sci_consensus'].fillna('none', inplace=True)\n",
    "df['worry'].fillna('none', inplace=True)\n",
    "df['harm_personally'].fillna('none', inplace=True)\n",
    "df['harm_US'].fillna('none', inplace=True)\n",
    "df['harm_dev_countries'].fillna('none', inplace=True)\n",
    "df['harm_future_gen'].fillna('none', inplace=True)\n",
    "df['harm_plants_animals'].fillna('none', inplace=True)\n",
    "df['when_harm_US'].fillna('none', inplace=True)\n",
    "df['reg_CO2_pollutant'].fillna('none', inplace=True)\n",
    "df['reg_utilities'].fillna('none', inplace=True)\n",
    "df['fund_research'].fillna('none', inplace=True)\n",
    "df['discuss_GW'].fillna('none', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced8f247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No', \"Don't know\", 'none'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cause_recoded.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4013cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['wave', 'year', 'happening', 'cause_recoded', 'sci_consensus', 'worry',\n",
       "       'harm_personally', 'harm_US', 'harm_dev_countries', 'harm_future_gen',\n",
       "       'harm_plants_animals', 'when_harm_US', 'reg_CO2_pollutant',\n",
       "       'reg_utilities', 'fund_research', 'discuss_GW', 'gender', 'age',\n",
       "       'generation', 'educ_category', 'income_category', 'party',\n",
       "       'party_x_ideo', 'region4', 'religion', 'service_attendance',\n",
       "       'marit_status', 'employment', 'house_head', 'house_size',\n",
       "       'house_ages0to1', 'house_ages2to5', 'house_ages6to12',\n",
       "       'house_ages18plus', 'house_type', 'house_own', 'age_category_35_54',\n",
       "       'age_category_55_plus', 'children'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12146f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22121\n",
       "Name: worry, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.worry.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4847aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:18.919937Z",
     "start_time": "2022-06-25T16:52:18.571414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ordinal encoding these features\n",
    "\n",
    "# the list of columns to ordinal\n",
    "df_ord = df[['year','wave', 'cause_recoded', 'sci_consensus',\n",
    "             'harm_personally', 'harm_US', 'harm_dev_countries',\n",
    "             'harm_future_gen', 'harm_plants_animals', 'when_harm_US', \n",
    "             'generation', 'educ_category', 'income_category',\n",
    "             'reg_CO2_pollutant','reg_utilities', 'fund_research', \n",
    "             'discuss_GW']]\n",
    "\n",
    "# have first spot be 'none' for features that got nulls changed\n",
    "# have first spot be '' for features with no nulls changed\n",
    "# this allows us to peel off nulls by removing all 0 encoded ordinals\n",
    "dogs = [[-999,2008, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018],\n",
    "        ['','2008 Nov', '2010 Jan', '2010 Jun', '2011 May', '2011 Nov', \n",
    "         '2012 Mar', '2012 Sep', '2013 Apr', '2013 Nov', '2014 Apr',\n",
    "         '2014 Oct', '2015 Mar', '2015 Oct', '2016 Mar', '2016 Nov',\n",
    "         '2017 May', '2017 Oct', '2018 Mar', '2018 Dec',],\n",
    "# cause_rec\n",
    "        ['none', 'No', \"Don't know\", 'Yes'],\n",
    "# sci_cons\n",
    "        ['none', 'No', \"Don't know\", 'Maybe', 'Yes'],\n",
    "\n",
    "        ['none','No',\"Don't know\", 'Yes'],\n",
    "        ['none','No',\"Don't know\", 'Yes'],\n",
    "        ['none','No',\"Don't know\", 'Yes'],\n",
    "        ['none','No',\"Don't know\", 'Yes'],\n",
    "        ['none','No',\"Don't know\", 'Yes'],\n",
    "        ['none','Never', 'In the Future', 'Now'],\n",
    "# gen\n",
    "        ['','Greatest (Before 1928)','Silent (1928 - 1945)',\n",
    "         'Baby Boomers (1946 - 1964)',\n",
    "         'Generation X (1965 - 1980)',\n",
    "         'Millennials (1981 - 1996)',\n",
    "         'iGen\\u200e/Gen Z (1997 - )'],\n",
    "# ed\n",
    "        ['','Less than high school',\n",
    "         'High school',\n",
    "         'Some college',\n",
    "         'Bachelor\\'s degree or higher'],\n",
    "# income        \n",
    "        ['','Less than $50,000',\n",
    "         '$50,000 to $99,999',\n",
    "         '$100,000 or more'],\n",
    "        \n",
    "        ['none','Oppose', 'Support'],\n",
    "        ['none','Oppose', 'Support'],\n",
    "        ['none','Oppose', 'Support'],\n",
    "        ['none','Never', 'At All']]\n",
    "\n",
    "\n",
    "# initialize\n",
    "o_enc = OrdinalEncoder(categories=dogs) \n",
    "\n",
    "# fit transform\n",
    "X_ord = o_enc.fit_transform(df_ord)\n",
    "\n",
    "# add to df\n",
    "# col names are original names + '_ord'\n",
    "X_ord_df = pd.DataFrame(X_ord,\n",
    "                        columns = [col+'_ord' for col in df_ord.columns])\\\n",
    "                .applymap(lambda x: np.nan if x == 0 else x)\n",
    "\n",
    "# drop non-ordinal cols for ordinal cols\n",
    "df = df.drop(df_ord.columns, axis = 1).join(X_ord_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "898f3d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  3., ...,  2.,  2.,  2.],\n",
       "       [ 1.,  1.,  3., ...,  2.,  2.,  2.],\n",
       "       [ 1.,  1.,  3., ...,  1.,  1.,  1.],\n",
       "       ...,\n",
       "       [10., 19.,  3., ...,  2.,  2.,  2.],\n",
       "       [10., 19.,  3., ...,  2.,  2.,  1.],\n",
       "       [10., 19.,  1., ...,  1.,  2.,  2.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122352c2",
   "metadata": {},
   "source": [
    "### Dummy encoding remaining features and adding features that were already ordinal encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56600ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_df = df[['party', 'party_x_ideo', 'region4', \n",
    "             'religion','marit_status', 'employment', 'house_head',\n",
    "             'house_type', 'house_own']]\n",
    "\n",
    "rdy_to_go = df[['house_ages18plus', 'children', 'service_attendance', 'house_size']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b7eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_df = pd.get_dummies(dum_df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d811c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_df = pd.concat([dum_df, rdy_to_go],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b419e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['party', 'party_x_ideo', 'region4', \n",
    "         'religion','marit_status', 'employment', 'house_head',\n",
    "         'house_type', 'house_own','house_ages18plus',\n",
    "         'children', 'service_attendance', 'house_size'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb648898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, additional_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f99496",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab3562f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:18.983937Z",
     "start_time": "2022-06-25T16:52:18.921937Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54c0bd75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:19.015938Z",
     "start_time": "2022-06-25T16:52:18.986937Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df.happening\n",
    "X = df[[cols for cols in df.columns if cols != \"happening\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d71ac58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:19.047006Z",
     "start_time": "2022-06-25T16:52:19.017937Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   test_size = 0.20,\n",
    "                                                   random_state = 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfafc8a",
   "metadata": {},
   "source": [
    "### Iteratively Impute Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5098137",
   "metadata": {},
   "source": [
    "Now all of our data is ordinal encoded or dummied, iteratively impute the nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71315c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:19.234259Z",
     "start_time": "2022-06-25T16:52:19.049939Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaa31393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:19.330223Z",
     "start_time": "2022-06-25T16:52:19.239226Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify numerical columns\n",
    "cols = X_train.describe().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98835b25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:19.362225Z",
     "start_time": "2022-06-25T16:52:19.332230Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify columns that will have nulls imputed\n",
    "cols_with_indicator = X_train[cols].loc[:,X_train[cols].isnull().any()].columns\n",
    "\n",
    "# rename them\n",
    "cols_with_indicator = [c+'_ind' for c in cols_with_indicator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df5107b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:19.394225Z",
     "start_time": "2022-06-25T16:52:19.365224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these columns still need to be encoded\n",
    "[c for c in X_train.columns if c not in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46c8da52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:19.410232Z",
     "start_time": "2022-06-25T16:52:19.397224Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "it_imp = IterativeImputer(initial_strategy='mean',\n",
    "                              add_indicator=True,\n",
    "                              random_state = 21\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "262c1fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:24.604516Z",
     "start_time": "2022-06-25T16:52:19.413240Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit on train\n",
    "X_train_it_imp = pd.DataFrame(it_imp.fit_transform(X_train[cols]),\n",
    "                columns = X_train[cols].columns.to_list()+cols_with_indicator)\n",
    "\n",
    "# transform test\n",
    "X_test_it_imp = pd.DataFrame(it_imp.transform(X_test[cols]),\n",
    "            columns = X_train[cols].columns.to_list()+cols_with_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2acfc694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:24.652516Z",
     "start_time": "2022-06-25T16:52:24.607515Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(cols, axis = 1).join(X_train_it_imp)\n",
    "X_test = X_test.drop(cols, axis = 1).join(X_test_it_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6fff5",
   "metadata": {},
   "source": [
    "### Standard Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e16ffc",
   "metadata": {},
   "source": [
    "Will let us explore knn or clustering if wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21e51cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:24.668522Z",
     "start_time": "2022-06-25T16:52:24.655516Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "972a51ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:24.732515Z",
     "start_time": "2022-06-25T16:52:24.670515Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "ss = StandardScaler()\n",
    "\n",
    "# fit on Train\n",
    "X_train_ss = pd.DataFrame(ss.fit_transform(X_train[cols]),\n",
    "                          columns = X_train[cols].columns)\n",
    "\n",
    "# transform test\n",
    "X_test_ss = pd.DataFrame(ss.transform(X_test[cols]),\n",
    "                         columns = X_test[cols].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50e81198",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:24.764520Z",
     "start_time": "2022-06-25T16:52:24.734517Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_ss = X_train.drop(cols, axis = 1).join(X_train_ss)\n",
    "X_test_ss = X_test.drop(cols, axis = 1).join(X_test_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f03efb",
   "metadata": {},
   "source": [
    "## Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97d0f733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:52:27.458520Z",
     "start_time": "2022-06-25T16:52:24.766547Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.to_csv('../data/y_train_processed.csv', index=False)\n",
    "y_test.to_csv('../data/y_train_processed.csv', index=False)\n",
    "\n",
    "X_train.to_csv('../data/x_train_processed.csv', index=False)\n",
    "X_test.to_csv('../data/x_test_processed.csv', index=False)\n",
    "\n",
    "X_train_ss.to_csv('../data/x_train_ss_processed.csv', index=False)\n",
    "X_test_ss.to_csv('../data/x_test_ss_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
